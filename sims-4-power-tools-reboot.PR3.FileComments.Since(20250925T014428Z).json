[
  {
    "path": "scripts/collect-metadata.js",
    "body": "![high](https://www.gstatic.com/codereviewagent/high-priority.svg)\n\nThe argument parsing for `--output` is not fully robust. If `--output` is the last argument, or if the next argument is another option (e.g., `--help`), it will lead to incorrect behavior. It's best to validate that a valid file path is provided.\n\n```javascript\n      if (i + 1 >= args.length || args[i + 1].startsWith('-')) {\n        throw new Error(`The ${arg} option requires a file path argument.`);\n      }\n      options.output = args[i + 1];\n      i++;\n```",
    "user": {
      "login": "gemini-code-assist[bot]"
    },
    "created_at": "2025-09-25T02:05:34Z"
  },
  {
    "path": "src/metadata.ts",
    "body": "![high](https://www.gstatic.com/codereviewagent/high-priority.svg)\n\nThe `collectPackagesMetadata` function processes files sequentially due to the `await` inside the `for...of` loop. For a batch operation, this is inefficient. Processing files in parallel using `Promise.all` would significantly improve performance. The error handling can be preserved to provide context on which file failed.\n\n```typescript\nexport async function collectPackagesMetadata(filePaths: readonly string[]): Promise<OriginalPackageInfo[]> {\n  const promises = filePaths.map(filePath =>\n    collectPackageMetadata(filePath).catch(error => {\n      // Re-throw a more specific error to identify which file failed.\n      throw new MetadataError(\n        `Failed to process package \"${filePath}\": ${error instanceof Error ? error.message : String(error)}`,\n        error\n      );\n    })\n  );\n\n  return Promise.all(promises);\n}\n```",
    "user": {
      "login": "gemini-code-assist[bot]"
    },
    "created_at": "2025-09-25T02:05:34Z"
  },
  {
    "path": "scripts/collect-metadata.js",
    "body": "![medium](https://www.gstatic.com/codereviewagent/medium-priority.svg)\n\nThere are several unused imports in this file (`basename`, `collectPackagesMetadata`). Additionally, if you apply the feedback to remove the redundant `validatePackage` call, that import will also become unused. It's good practice to remove unused imports to keep the code clean.\n\n```javascript\nimport { resolve } from 'node:path';\nimport { collectPackageMetadata } from '../dist/metadata.js';\n```",
    "user": {
      "login": "gemini-code-assist[bot]"
    },
    "created_at": "2025-09-25T02:05:34Z"
  },
  {
    "path": "scripts/collect-metadata.js",
    "body": "![medium](https://www.gstatic.com/codereviewagent/medium-priority.svg)\n\nThe script reads and parses the package file twice: once in `collectPackageMetadata` and again in `validatePackage`. This is inefficient. All the necessary validation information can be obtained from the first call if `totalSize` is added to the `OriginalPackageInfo` type. This would also allow you to remove the `validatePackage` import and call.\n\nI recommend the following changes:\n1.  Add `readonly totalSize: number;` to the `OriginalPackageInfo` interface in `src/types/metadata.ts`.\n2.  Return `totalSize: structure.totalSize` from `collectPackageMetadata` in `src/metadata.ts`.\n3.  Update this script to use the `metadata` object for validation info.\n\n```javascript\n    console.log('\\nValidation:');\n    console.log(`- Filename: ${metadata.filename}`);\n    console.log(`- SHA256: ${metadata.sha256}`);\n    console.log(`- Resources: ${metadata.resources.length}`);\n    console.log(`- Size: ${metadata.totalSize} bytes`);\n```",
    "user": {
      "login": "gemini-code-assist[bot]"
    },
    "created_at": "2025-09-25T02:05:34Z"
  },
  {
    "path": "src/metadata.ts",
    "body": "![medium](https://www.gstatic.com/codereviewagent/medium-priority.svg)\n\nThe `validatePackage` function returns an anonymous object type. Defining a named interface for this return type (e.g., `PackageValidationInfo`) would make the code more self-documenting, maintainable, and reusable.\n\n```typescript\nexport interface PackageValidationInfo {\n  filename: string;\n  sha256: string;\n  resourceCount: number;\n  totalSize: number;\n}\n\nexport async function validatePackage(filePath: string): Promise<PackageValidationInfo> {\n```",
    "user": {
      "login": "gemini-code-assist[bot]"
    },
    "created_at": "2025-09-25T02:05:34Z"
  },
  {
    "path": "scripts/collect-metadata.js",
    "body": "_‚ö†Ô∏è Potential issue_\n\n**Directory inputs currently break the CLI**\n\n`collectPackageMetadata` is invoked unconditionally, so passing a directory (which the usage banner explicitly documents) bubbles straight into `DbpfBinary.read`, which then fails with an ENOENT. That means the advertised directory workflow is dead on arrival. Please branch on `stat(inputPath).isDirectory()` and feed the discovered `.package` files through `collectPackagesMetadata`, emitting aggregated JSON plus per-package validation, so directory mode actually works.\n\n\n\nApply something along these lines:\n\n```diff\n-import { writeFile } from 'node:fs/promises';\n+import { readdir, stat, writeFile } from 'node:fs/promises';\n@@\n-  const inputPath = resolve(options.input);\n+  const inputPath = resolve(options.input);\n+  const inputStats = await stat(inputPath);\n@@\n-    console.log(`Collecting metadata from: ${inputPath}`);\n-\n-    const metadata = await collectPackageMetadata(inputPath);\n+    console.log(`Collecting metadata from: ${inputPath}`);\n+\n+    const replacer = (key, value) => {\n+      if (typeof value === 'bigint') {\n+        return `0x${value.toString(16)}`;\n+      }\n+      if (typeof value === 'number' && (key === 'type' || key === 'group' || key === 'instance')) {\n+        return `0x${value.toString(16)}`;\n+      }\n+      return value;\n+    };\n+\n+    if (inputStats.isDirectory()) {\n+      const entries = await readdir(inputPath, { withFileTypes: true });\n+      const packageFiles = entries\n+        .filter((entry) => entry.isFile() && entry.name.toLowerCase().endsWith('.package'))\n+        .map((entry) => resolve(inputPath, entry.name));\n+\n+      if (packageFiles.length === 0) {\n+        console.warn('No .package files found in directory.');\n+        return;\n+      }\n+\n+      const metadataList = await collectPackagesMetadata(packageFiles);\n+      const jsonOutput = JSON.stringify(metadataList, replacer, 2);\n+      if (options.output) {\n+        const outputPath = resolve(options.output);\n+        await writeFile(outputPath, jsonOutput, 'utf8');\n+        console.log(`Metadata written to: ${outputPath}`);\n+      } else {\n+        console.log(jsonOutput);\n+      }\n+\n+      console.log('\\nValidation:');\n+      for (const packagePath of packageFiles) {\n+        const validation = await validatePackage(packagePath);\n+        console.log(`- ${validation.filename}: ${validation.resourceCount} resources, ${validation.totalSize} bytes, sha256=${validation.sha256}`);\n+      }\n+      return;\n+    }\n+\n+    const metadata = await collectPackageMetadata(inputPath);\n@@\n-    const jsonOutput = JSON.stringify(metadata, (key, value) => {\n-      if (typeof value === 'bigint') {\n-        return '0x' + value.toString(16);\n-      }\n-      // Convert numbers in TGI objects to hex\n-      if (typeof value === 'number' && key && (key === 'type' || key === 'group' || key === 'instance')) {\n-        return '0x' + value.toString(16);\n-      }\n-      return value;\n-    }, 2);\n+    const jsonOutput = JSON.stringify(metadata, replacer, 2);\n```\n\n<!-- suggestion_start -->\n\n<details>\n<summary>üìù Committable suggestion</summary>\n\n> ‚ÄºÔ∏è **IMPORTANT**\n> Carefully review the code before committing. Ensure that it accurately replaces the highlighted code, contains no missing lines, and has no issues with indentation. Thoroughly test & benchmark the code to ensure it meets the requirements.\n\n```suggestion\n  const inputPath = resolve(options.input);\n  const inputStats = await stat(inputPath);\n\n  try {\n    // For now, let's just collect metadata from a single file\n    // TODO: Add directory support as mentioned in the task\n    console.log(`Collecting metadata from: ${inputPath}`);\n\n    const replacer = (key, value) => {\n      if (typeof value === 'bigint') {\n        return `0x${value.toString(16)}`;\n      }\n      if (typeof value === 'number' && (key === 'type' || key === 'group' || key === 'instance')) {\n        return `0x${value.toString(16)}`;\n      }\n      return value;\n    };\n\n    if (inputStats.isDirectory()) {\n      const entries = await readdir(inputPath, { withFileTypes: true });\n      const packageFiles = entries\n        .filter(entry => entry.isFile() && entry.name.toLowerCase().endsWith('.package'))\n        .map(entry => resolve(inputPath, entry.name));\n\n      if (packageFiles.length === 0) {\n        console.warn('No .package files found in directory.');\n        return;\n      }\n\n      const metadataList = await collectPackagesMetadata(packageFiles);\n      const jsonOutput = JSON.stringify(metadataList, replacer, 2);\n\n      if (options.output) {\n        const outputPath = resolve(options.output);\n        await writeFile(outputPath, jsonOutput, 'utf8');\n        console.log(`Metadata written to: ${outputPath}`);\n      } else {\n        console.log(jsonOutput);\n      }\n\n      console.log('\\nValidation:');\n      for (const pkgPath of packageFiles) {\n        const validation = await validatePackage(pkgPath);\n        console.log(\n          `- ${validation.filename}: ` +\n          `${validation.resourceCount} resources, ` +\n          `${validation.totalSize} bytes, ` +\n          `sha256=${validation.sha256}`\n        );\n      }\n      return;\n    }\n\n    const metadata = await collectPackageMetadata(inputPath);\n\n    // Pretty print the metadata (handle BigInts and hex conversion for JSON serialization)\n    const jsonOutput = JSON.stringify(metadata, replacer, 2);\n\n    if (options.output) {\n      const outputPath = resolve(options.output);\n      await writeFile(outputPath, jsonOutput, 'utf8');\n      console.log(`Metadata written to: ${outputPath}`);\n    } else {\n      console.log(jsonOutput);\n    }\n\n    // Also show validation info\n    console.log('\\nValidation:');\n    const validation = await validatePackage(inputPath);\n    console.log(`- Filename: ${validation.filename}`);\n    console.log(`- SHA256: ${validation.sha256}`);\n    console.log(`- Resources: ${validation.resourceCount}`);\n    console.log(`- Size: ${validation.totalSize} bytes`);\n```\n\n</details>\n\n<!-- suggestion_end -->\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn scripts/collect-metadata.js around lines 67 to 103, the CLI currently calls\ncollectPackageMetadata unconditionally which fails for directory inputs; update\nthe flow to first await stat(inputPath) and if stat.isDirectory() then\nrecursively or non-recursively discover .package files (e.g., readdir + filter\nfor /\\.package$/), call collectPackagesMetadata or iterate and call\ncollectPackageMetadata for each discovered file to build an aggregated metadata\narray/object, run validatePackage for each package to produce per-package\nvalidation info, and then serialize and write or print the aggregated JSON and\nthe per-package validation summaries exactly like the file case; also handle\nempty directory (emit an error/exit or informative message) and ensure all file\nI/O and metadata/validation calls are awaited and errors are logged before\nexiting.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:sabertoothed -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->",
    "user": {
      "login": "coderabbitai[bot]"
    },
    "created_at": "2025-09-25T02:10:02Z"
  },
  {
    "path": "src/metadata.ts",
    "body": "_‚ö†Ô∏è Potential issue_\n\n**Use the preserved original offset**\n\nWe expose an `originalOffset` field but populate it with `resource.offset`, which is the post-normalisation value (and may differ from the on-disk offset when S4TK corrects metadata). Consumers relying on the true original position now get the wrong number. Switch to `resource.originalOffset`, which is already captured for exactly this purpose.\n\n\n\n```diff\n-      originalOffset: resource.offset,\n+      originalOffset: resource.originalOffset,\n```\n\n<details>\n<summary>ü§ñ Prompt for AI Agents</summary>\n\n```\nIn src/metadata.ts around lines 29 to 38, the code sets originalOffset to\nresource.offset (post-normalisation) instead of the preserved on-disk value;\nupdate the assignment to use resource.originalOffset so consumers get the true\noriginal file position, leaving all other fields unchanged.\n```\n\n</details>\n\n<!-- fingerprinting:phantom:poseidon:sabertoothed -->\n\n<!-- This is an auto-generated comment by CodeRabbit -->",
    "user": {
      "login": "coderabbitai[bot]"
    },
    "created_at": "2025-09-25T02:10:02Z"
  }
]